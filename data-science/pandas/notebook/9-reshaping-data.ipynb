{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining, Relating, and Reshaping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two Series objects to concatenate\n",
    "s1 = pd.Series(np.arange(0, 3))\n",
    "s2 = pd.Series(np.arange(5, 8))\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate them, index labels are duplicated\n",
    "pd.concat([s1, s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two DataFrame objects to concatenate\n",
    "# using the same index labels and column names, \n",
    "# but different values\n",
    "df1 = pd.DataFrame(np.arange(9).reshape(3, 3), \n",
    "                   columns=['a', 'b', 'c'])\n",
    "#df2 has 9 .. 18\n",
    "df2 = pd.DataFrame(np.arange(9, 18).reshape(3, 3), \n",
    "                   columns=['a', 'b', 'c'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the concat\n",
    "# the result has index labels duplicated along the rows index\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate concatenating two DataFrame objects with\n",
    "# different columns\n",
    "df1 = pd.DataFrame(np.arange(9).reshape(3, 3), \n",
    "                   columns=['a', 'b', 'c'])\n",
    "df2 = pd.DataFrame(np.arange(9, 18).reshape(3, 3), \n",
    "                   columns=['a', 'c', 'd'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the concat, NaN's will be filled in for\n",
    "# the d column for df1 and b column for df2\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the two objects, but create an index using the\n",
    "# given keys \n",
    "c = pd.concat([df1, df2], keys=['df1', 'df2'])\n",
    "# note in the labeling of the rows in the output\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can extract the data originating from\n",
    "# the first or second source DataFrame\n",
    "c.loc['df2']"
   ]
  },
  {
   "source": [
    "### Switching axes of alignment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat df1 and df2 along columns\n",
    "# aligns on row labels, has duplicate columns\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a new DataFrame to merge with df1\n",
    "# this has two common row labels (2, 3) \n",
    "# common columns (a) and one disjoint column\n",
    "# in each (b in df1 and d in df2)\n",
    "df3 = pd.DataFrame(np.arange(20, 26).reshape(3, 2), \n",
    "                   columns=['a', 'd'], \n",
    "                   index=[2, 3, 4])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat them. Alignment is along row labels\n",
    "# columns first from df1 and then df3, with duplicates.\n",
    "# NaN filled in where those columns do not exist in the source\n",
    "pd.concat([df1, df3], axis=1)"
   ]
  },
  {
   "source": [
    "### Specifying join type"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do an inner join instead of outer\n",
    "# results in one row, because 2 is the only row index label in common\n",
    "pd.concat([df1, df3], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add keys to the columns\n",
    "df = pd.concat([df1, df2], \n",
    "               axis=1,\n",
    "               keys=['df1', 'df2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the data that originated from the \n",
    "# DataFrame with key 'df2'\n",
    "df.loc[:, 'df2']"
   ]
  },
  {
   "source": [
    "### Appending versus concatenation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append does a concatenate along axis=0 \n",
    "# duplicate row index labels can result\n",
    "df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates in the result index\n",
    "df1.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An overview of merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are our customers\n",
    "customers = {'CustomerID': [10, 11],\n",
    "             'Name': ['Mike', 'Marcia'],\n",
    "             'Address': ['Address for Mike',\n",
    "                         'Address for Marcia']}\n",
    "customers = pd.DataFrame(customers)\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and these are the orders made by our customers\n",
    "# they are related to customers by CustomerID\n",
    "orders = {'CustomerID': [10, 11, 10],\n",
    "          'OrderDate': [date(2014, 12, 1),\n",
    "                        date(2014, 12, 1),\n",
    "                        date(2014, 12, 1)]}\n",
    "orders = pd.DataFrame(orders)\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge customers and orders so we can ship the items\n",
    "customers.merge(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to be used in the remainder of this section's examples\n",
    "left_data = {'key1': ['a', 'b', 'c'], \n",
    "            'key2': ['x', 'y', 'z'],\n",
    "            'lval1': [ 0, 1, 2]}\n",
    "right_data = {'key1': ['a', 'b', 'c'],\n",
    "              'key2': ['x', 'a', 'z'], \n",
    "              'rval1': [ 6, 7, 8 ]}\n",
    "left = pd.DataFrame(left_data, index=[0, 1, 2])\n",
    "right = pd.DataFrame(right_data, index=[1, 2, 3])\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate merge without specifying columns to merge\n",
    "# this will implicitly merge on all common columns\n",
    "left.merge(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate merge using an explicit column\n",
    "# on needs the value to be in both DataFrame objects\n",
    "left.merge(right, on='key1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge explicitly using two columns\n",
    "left.merge(right, on=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join on the row indices of both matrices\n",
    "pd.merge(left, right, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the join semantics of a merge operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join, merges all matched data, \n",
    "# and fills unmatched items with NaN\n",
    "left.merge(right, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join, merges all matched data, and only fills unmatched \n",
    "# items from the left dataframe with NaN filled for the \n",
    "# unmatched items in the result \n",
    "# rows with labels 0 and 2 \n",
    "# match on key1 and key2 the row with label 1 is from left\n",
    "\n",
    "left.merge(right, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right join, merges all matched data, and only fills unmatched\n",
    "# item from the right with NaN filled for the unmatched items\n",
    "# in the result \n",
    "# rows with labels 0 and 2 match on key1 and key2\n",
    "# the row with label 1 is from right\n",
    "left.merge(right, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join left with right (default method is outer) using the index labels\n",
    "# and since these DataFrame objects have duplicate column names\n",
    "# we just specify lsuffix and rsuffix\n",
    "left.join(right, lsuffix='_left', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join left with right with an inner join\n",
    "left.join(right, lsuffix='_left', rsuffix='_right', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in accelerometer data\n",
    "sensor_readings = pd.read_csv(\"data/accel.csv\")\n",
    "sensor_readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Y-axis readings\n",
    "sensor_readings[sensor_readings['axis'] == 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the data. Interval becomes the index, the columns are\n",
    "# the current axes values, and use the readings as values\n",
    "sensor_readings.pivot(index='interval', \n",
    "                     columns='axis', \n",
    "                     values='reading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking using non-hierarchical indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple DataFrame with one column\n",
    "df = pd.DataFrame({'a': [1, 2]}, index={'one', 'two'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the column to another level of the index\n",
    "# the result is a Series where values are looked up through\n",
    "# a multi-index\n",
    "stacked1 = df.stack()\n",
    "stacked1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup one / a using just the index via a tuple\n",
    "stacked1[('one', 'a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with two columns\n",
    "df = pd.DataFrame({'a': [1, 2],\n",
    "                   'b': [3, 4]}, \n",
    "                  index={'one', 'two'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the two columns into a single level of the index\n",
    "stacked2 = df.stack()\n",
    "stacked2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup value with index of one / b\n",
    "stacked2[('one', 'b')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstacking using hierarchical indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make two copies of the sensor data, one for each user\n",
    "user1 = sensor_readings.copy()\n",
    "user2 = sensor_readings.copy()\n",
    "# add names to the two copies\n",
    "user1['who'] = 'Mike'\n",
    "user2['who'] = 'Mikael'\n",
    "# for demonstration, lets scale user2's readings\n",
    "user2['reading'] *= 100\n",
    "# and reorganize this to have a hierarchical row index\n",
    "multi_user_sensor_data = pd.concat([user1, user2]) \\\n",
    "            .set_index(['who', 'interval', 'axis'])\n",
    "multi_user_sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup user data for Mike using just the index\n",
    "multi_user_sensor_data.loc['Mike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readings for all users and axes at interval 1\n",
    "multi_user_sensor_data.xs(1, level='interval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack the who level\n",
    "multi_user_sensor_data.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack at level=0\n",
    "multi_user_sensor_data.unstack(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack who and axis levels\n",
    "unstacked = multi_user_sensor_data.unstack(['who', 'axis'])\n",
    "unstacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we can of course stack what we have unstacked\n",
    "# this re-stacks who\n",
    "unstacked.stack(level='who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will demonstrate melting with this DataFrame\n",
    "data = pd.DataFrame({'Name' : ['Mike', 'Mikael'],\n",
    "                     'Height' : [6.1, 6.0],\n",
    "                     'Weight' : [220, 185]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt it, use Name as the id's, \n",
    "# Height and Weight columns as the variables\n",
    "pd.melt(data, \n",
    "        id_vars=['Name'],\n",
    "        value_vars=['Height', 'Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance benefits of stacked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked scalar access can be a lot faster than\n",
    "# column access\n",
    "\n",
    "# time the different methods\n",
    "import timeit\n",
    "t = timeit.Timer(\"stacked1[('one', 'a')]\", \n",
    "                 \"from __main__ import stacked1, df\")\n",
    "r1 = timeit.timeit(lambda: stacked1.loc[('one', 'a')], \n",
    "                   number=10000)\n",
    "r2 = timeit.timeit(lambda: df.loc['one']['a'], \n",
    "                   number=10000)\n",
    "r3 = timeit.timeit(lambda: df.iloc[1, 0], \n",
    "                   number=10000)\n",
    "\n",
    "# and the results are...  Yes, it's the fastest of the three\n",
    "r1, r2, r3"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python380jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.8.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}