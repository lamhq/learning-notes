{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a CSV into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in msft.csv into a DataFrame\n",
    "msft = pd.read_csv(\"data/msft.csv\")\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the index column when reading a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use column 0 as the index\n",
    "msft = pd.read_csv(\"data/msft.csv\", index_col=0)\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data type inference and specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the types of the columns in this DataFrame\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify that the Volume column should be a float64\n",
    "msft = pd.read_csv(\"data/msft.csv\", \n",
    "                   dtype = { 'Volume' : np.float64})\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify a new set of names for the columns\n",
    "# all lower case, remove space in Adj Close\n",
    "# also, header=0 skips the header row\n",
    "df = pd.read_csv(\"data/msft.csv\", \n",
    "                 header=0,\n",
    "                 names=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying specific columns to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in data only in the Date and Close columns\n",
    "# and index by the Date column\n",
    "df2 = pd.read_csv(\"data/msft.csv\", \n",
    "                  usecols=['Date', 'Close'], \n",
    "                  index_col=['Date'])\n",
    "df2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a DataFrame to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save df2 to a new csv file\n",
    "# also specify naming the index as date\n",
    "df2.to_csv(\"data/msft_modified.csv\", index_label='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General field-delimited data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use read_table with sep=',' to read a CSV\n",
    "df = pd.read_table(\"data/msft.csv\", sep=',')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save as pipe delimited\n",
    "df.to_csv(\"data/msft_piped.txt\", sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling messy data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# messy file\n",
    "!head -n 6 data/msft2.csv # osx or Linux\n",
    "# type data/msft2.csv # windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read, but skip rows 0, 2 and 3\n",
    "df = pd.read_csv(\"data/msft2.csv\", skiprows=[0, 2, 3])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# another messy file, with the mess at the end\n",
    "!cat data/msft_with_footer.csv # osx or Linux\n",
    "# type data/msft_with_footer.csv # windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# skip only two lines at the end\n",
    "df = pd.read_csv(\"data/msft_with_footer.csv\", \n",
    "                 skipfooter=2,\n",
    "                 engine = 'python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only process the first three rows\n",
    "pd.read_csv(\"data/msft.csv\", nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# skip 100 lines, then only process the next five\n",
    "pd.read_csv(\"data/msft.csv\", skiprows=100, nrows=5, \n",
    "            header=0,\n",
    "            names=['date', 'open', 'high', 'low', 'close', 'vol']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing data in Excel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read excel file, it require `openpyxl` package\n",
    "# only reads first sheet (msft in this case)\n",
    "df = pd.read_excel(\"data/stocks.xlsx\")\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read from the aapl worksheet\n",
    "aapl = pd.read_excel(\"data/stocks.xlsx\", sheet_name='aapl')\n",
    "aapl[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to an .XLS file, in worksheet 'Sheet1'\n",
    "df.to_excel(\"data/stocks2.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write making the worksheet name MSFT\n",
    "df.to_excel(\"data/stocks_msft.xls\", sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write multiple sheets\n",
    "# requires use of the ExcelWriter class\n",
    "from pandas import ExcelWriter\n",
    "with ExcelWriter(\"data/all_stocks.xls\") as writer:\n",
    "    aapl.to_excel(writer, sheet_name='AAPL')\n",
    "    df.to_excel(writer, sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to xlsx\n",
    "df.to_excel(\"data/msft2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wirite the excel data to a JSON file\n",
    "df[:5].to_json(\"data/stocks.json\")\n",
    "!cat data/stocks.json # osx or Linux\n",
    "#type data/stocks.json # windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data in from JSON\n",
    "df_from_json = pd.read_json(\"https://raw.githubusercontent.com/PacktPublishing/Learning-Pandas-Second-Edition/master/data/stocks.json\")\n",
    "df_from_json[:5]"
   ]
  },
  {
   "source": [
    "## Reading and writing HTML files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the URL to read, require `lxml` package\n",
    "url = \"http://www.fdic.gov/bank/individual/failed/banklist.html\"\n",
    "# read it\n",
    "banks = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine a subset of the first table read\n",
    "banks[0][0:5].iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the stock data\n",
    "df = pd.read_excel(\"data/stocks.xlsx\")\n",
    "# write the first two rows to HTML\n",
    "df.head(2).to_html(\"data/stocks.html\")\n",
    "# check the first 28 lines of the output\n",
    "!head -n 10 data/stocks.html # max or Linux\n",
    "# type data/stocks.html # window, but prints the entire file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing CSV data on the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read csv directly from Yahoo! Finance from a URL\n",
    "msft_hist = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/PacktPublishing/Learning-Pandas-Second-Edition/master/data/msft.csv\")\n",
    "msft_hist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to SQL databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reference SQLite\n",
    "import sqlite3\n",
    "\n",
    "# read in the stock data from CSV\n",
    "msft = pd.read_csv(\"data/msft.csv\")\n",
    "msft[\"Symbol\"]=\"MSFT\"\n",
    "aapl = pd.read_csv(\"data/aapl.csv\")\n",
    "aapl[\"Symbol\"]=\"AAPL\"\n",
    "\n",
    "# create connection\n",
    "connection = sqlite3.connect(\"data/stocks.sqlite\")\n",
    "# .to_sql() will create SQL to store the DataFrame\n",
    "# in the specified table.  if_exists specifies\n",
    "# what to do if the table already exists\n",
    "msft.to_sql(\"STOCK_DATA\", connection, if_exists=\"replace\")\n",
    "aapl.to_sql(\"STOCK_DATA\", connection, if_exists=\"append\")\n",
    "\n",
    "# commit the SQL and close the connection\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "source": [
    "## Reading from SQL databases"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connect to the database file\n",
    "connection = sqlite3.connect(\"data/stocks.sqlite\")\n",
    "\n",
    "# query all records in STOCK_DATA\n",
    "# returns a DataFrame\n",
    "# inde_col specifies which column to make the DataFrame index\n",
    "stocks = pd.io.sql.read_sql(\"SELECT * FROM STOCK_DATA;\", \n",
    "                             connection, index_col='index')\n",
    "\n",
    "# close the connection\n",
    "connection.close()\n",
    "\n",
    "# report the head of the data retrieved\n",
    "stocks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open the connection\n",
    "connection = sqlite3.connect(\"data/stocks.sqlite\")\n",
    "# construct the query string\n",
    "query = \"SELECT * FROM STOCK_DATA WHERE \" + \\\n",
    "        \"Volume>29200100 AND Symbol='MSFT';\"\n",
    "# execute and close connection\n",
    "items = pd.io.sql.read_sql(query, connection, index_col='index')\n",
    "connection.close()\n",
    "# report the query result\n",
    "items"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python380jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.8.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}